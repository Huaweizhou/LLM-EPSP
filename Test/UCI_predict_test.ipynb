{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义所需的API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from astropy.table import Table\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义初始变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"student-data.csv\"\n",
    "# FEW_SHOT_IDS = [\"19414\",\"19109\",\"19116\",\"23205\",\"23145\"]\n",
    "PROMPT_PATH = \"DEMO_PROMPT.txt\"\n",
    "LINE_DELIMITER = \"&&&\"\n",
    "ROLE_DELIMITER = \": \"\n",
    "IN_COLS = [\n",
    "    \"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\\\n",
    "    \"Fjob\",\"reason\",\"guardian\",\"traveltime\",\"studytime\",\"failures\",\"schoolsup\",\\\n",
    "    \"famsup\",\"paid\",\"activities\",\"nursery\",\"higher\",\"internet\",\"romantic\",\"famrel\",\\\n",
    "    \"freetime\",\"goout\",\"Dalc\",\"Walc\",\"health\",\"absences\",\"passedsex\",\"age\",\"address\",\\\n",
    "    \"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"guardian\",\"traveltime\",\\\n",
    "    \"studytime\",\"failures\",\"schoolsup\",\"famsup\",\"paid\",\"activities\",\"nursery\",\"higher\",\\\n",
    "    \"internet\",\"romantic\",\"famrel\",\"freetime\",\"goout\",\"Dalc\",\"Walc\",\"health\",\"absences\",\"passed\"\n",
    "]\n",
    "\n",
    "# OPEN_AI_API_KEY = \"sk-GXrNK1wppwsbwLr463C7Ab7749Cb4f61Be4d226f99Dd3467\"\n",
    "OPEN_AI_API_KEY = \"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\"\n",
    "\n",
    "# assert OPEN_AI_API_KEY\n",
    "MODEL = \"gpt-4\"\n",
    "\n",
    "GENERATIONS_PATH = \"DEMO_GENERATIONS.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据原始的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to expand column width in DataFrame for fuller viewing\n",
    "pd.set_option('max_colwidth', 40)\n",
    "pd.set_option('display.max_rows', 400)  \n",
    "\n",
    "df_all = pd.read_csv(DATA_PATH)\n",
    "assert not df_all.isnull().values.any()\n",
    "\n",
    "X = df_all.drop(columns=['passed'])\n",
    "y = df_all['passed']\n",
    "\n",
    "# 将数据集划分为训练集和验证集,并合并训练集的数据与标签，重新排序。\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_test = pd.concat([X_test, y_test],axis=1 )\n",
    "num_rows = df_train.shape[0]\n",
    "# print(\"\", df_train.iloc[:,0])\n",
    "df_train.iloc[1:, 0] = range(num_rows - 1)\n",
    "df_train.iloc[1:, 0] = 0\n",
    "\n",
    "# 检查训练集和验证集中是否有缺失值\n",
    "assert not X_train.isnull().values.any()\n",
    "assert not X_test.isnull().values.any() \n",
    "assert not y_train.isnull().values.any() \n",
    "assert not y_test.isnull().values.any() \n",
    "\n",
    "# print(f\"训练集特征大小: {X_train.shape}\")\n",
    "# print(f\"训练集标签大小: {y_train.shape}\")\n",
    "# print(f\"验证集特征大小: {X_test.shape}\")\n",
    "# print(f\"验证集标签大小: {y_test.shape}\") \n",
    "\n",
    "\n",
    "\n",
    "df_all.iloc[0].tolist()\n",
    "# df_all\n",
    "# df_train.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_low = data[data['grade'] == 0]\n",
    "df_medium = data[data['grade'] == 1]\n",
    "df_high = data[data['grade'] == 2]\n",
    "\n",
    "data_resample_low = resample(df_low,\n",
    "                replace = True,\n",
    "                n_samples = 200,\n",
    "                random_state = 1)\n",
    "\n",
    "data_resample_high = resample(df_high,\n",
    "                replace = True,\n",
    "                n_samples = 200,\n",
    "                random_state = 1)\n",
    "\n",
    "data2 = pd.concat([data_resample_low, df_medium, data_resample_high])\n",
    "\n",
    "data2['grade'].value_counts()\n",
    "\n",
    "\n",
    "# 可选的特征选取\n",
    "'https://github.com/AutoViML/featurewiz'\n",
    "'https://github.com/apachecn/ml-mastery-zh-pt2/blob/master/docs/dataprep/rfe-feature-selection-in-python.md'\n",
    "'best features technique and the ELI5 library'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### explain like i'm five ELI5特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import eli5\n",
    "# from eli5.sklearn import PermutationImportance\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 解释特征权重对预测的影响\n",
    "eli5.show_prediction(model, X_test.iloc[0], feature_names=IN_COLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## impot and setup prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROMPT_PATH,\"r\") as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xy_instance = df_train.to_dict(orient='records') # 转化为列表字典形式\n",
    "test_xy_instance = df_test.to_dict(orient='records')\n",
    "test_x_instance = X_test.to_dict(orient='records')\n",
    "print(test_xy_instance)\n",
    "# list_of_dicts[0]['school']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store messages\n",
    "messages_train = []\n",
    "\n",
    "# 遍历 train_xy_instance 列表\n",
    "for trainins in train_xy_instance:\n",
    "    # 创建第一种字典\n",
    "    system_dict = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"As an experienced high school teacher with years of teaching expertise, you excel at assessing students' attributes to predict their likelihood of passing the final course examination.\\\n",
    "                    You will be provided with multiple students' various attributes along with their final exam outcomes (whether they passed or not).\\\n",
    "                    Your task is to analyze this data, identify the most significant factors influencing students' ability to pass the exam,\\\n",
    "                    and then accurately predict whether a student will pass the exam based on their given attributes.\\\n",
    "                    \"\n",
    "    }\n",
    "    # 创建第二种字典\n",
    "    user_dict = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"You will first analyze and learn the various attributes of the student{trainins} \\\n",
    "                    Based on the final outcome of passed (yes/no), you need to determine the characteristics that indicate which students are likely to pass the exam and which are not.\"\n",
    "    }\n",
    "    # 将这两个字典添加到列表中\n",
    "    messages_train.append(system_dict)\n",
    "    messages_train.append(user_dict)\n",
    "\n",
    "# 输出生成的列表\n",
    "# messages_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test Messages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store messages\n",
    "messages_test = []\n",
    "\n",
    "# 遍历 train_xy_instance 列表\n",
    "for testins in test_x_instance:\n",
    "    # 创建第一种字典\n",
    "    system_dict = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"As an experienced high school teacher with years of teaching expertise, you excel at assessing students' attributes to predict their likelihood of passing the final course examination.\\\n",
    "                    You will be provided with multiple students' various attributes along with their final exam outcomes (whether they passed or not).\\\n",
    "                    Your task is to analyze this data, identify the most significant factors influencing students' ability to pass the exam,\\\n",
    "                    and then accurately predict whether a student will pass the exam based on their given attributes.\\\n",
    "                    \"\n",
    "    }\n",
    "    # 创建第二种字典\n",
    "    user_dict = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"You analyze and learn the various attributes of the student{testins} \\\n",
    "                    Based on the final outcome of passed (yes/no)\"\n",
    "    }\n",
    "    # 将这两个字典添加到列表中\n",
    "    messages_test.append(system_dict)\n",
    "    messages_test.append(user_dict)\n",
    "messages_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up GPT enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the OpenAI package downloaded in the cell above   \n",
    "import openai\n",
    "\n",
    "# Import textwrap to print without having to scroll l                         eft or right on screen\n",
    "import textwrap\n",
    "\n",
    "# Define OpenAI key\n",
    "openai.api_key = OPEN_AI_API_KEY\n",
    "\n",
    "# This statement tests the API call to make sure the API is working properly\n",
    "assert openai.Model.list()[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchian Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Get model response\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "# for test_ins in test_x_instance:\n",
    "for trainxy in train_xy_instance:\n",
    "  messages1 = [\n",
    "          SystemMessage(content=f\"1.As an experienced high school teacher with years of teaching expertise, you excel at assessing students' attributes to predict their likelihood of passing the final course examination.\\\n",
    "                                  You will be provided with multiple students' various attributes along with their final exam outcomes (whether they passed or not).\\\n",
    "                                  Your task is to analyze this data, identify the most significant factors influencing students' ability to pass the exam,\\\n",
    "                                  and then accurately predict whether a student will pass the exam based on their given attributes.\\\n",
    "                                  2.You will first analyze {trainxy}the various attributes of the student \\\n",
    "                                  Based on the final outcome of passed (yes/no), you need to determine the characteristics that indicate which students are likely to pass the exam and which are not.\\\n",
    "                                  \"),\n",
    "          # HumanMessage(content=f\"Given the attributes of this student{test_x_instance}, determine whether they will ultimately pass the exam.\\\n",
    "          #                        Respond with either yes or no. Only one of these options is acceptable.\")\n",
    "          HumanMessage(content=f\"请对所给例子进行学习\")\n",
    "      ]\n",
    "for testx in test_x_instance:\n",
    "  messages2 = [\n",
    "          SystemMessage(content=\"请将你在之前学习到的判断经验运用于下方学生的pass与否的判断\"),\n",
    "          HumanMessage(content=f\"Given the attributes of this student{testx}, determine whether they will ultimately pass the exam.\\\n",
    "                                 Respond with either yes or no. Only one of these options is acceptable.\")\n",
    "      ]\n",
    "response = llm.invoke(messages2)\n",
    "\n",
    "\n",
    "# THIS IS THE MODEL'S RESPONSE\n",
    "# generation = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "total_tokens = response[\"usage\"][\"total_tokens\"]\n",
    "\n",
    "# Add response generation to list\n",
    "# instance_i[\"prompt\"] = save_prompt\n",
    "# instance_i[\"n_few_shot\"] = N_FEW_SHOT\n",
    "# instance_i[\"model_generation\"] = generation\n",
    "# instance_i[\"total_tokens\"] = total_tokens\n",
    "# results.append(instance_i)\n",
    "\n",
    "# Track progress\n",
    "# if not i%5:\n",
    "#   print(f\"Finished instance {i}.\")\n",
    "\n",
    "# Sleep in between calls if needed 5 or 10 seconds, depending on prompt length\n",
    "time.sleep(5)\n",
    "\n",
    "print(\"FINISHED ALL INSTANCES.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = messages_train \n",
    "response = openai.ChatCompletion.create(\n",
    "model=MODEL,\n",
    "messages=messages,\n",
    "temperature = 0.0,\n",
    ")\n",
    "\n",
    "# THIS IS THE MODEL'S RESPONSE\n",
    "response\n",
    "generation = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "# API call token length information. This is used to track token limits\n",
    "#   and for calculating how long to sleep the script in between instances.\n",
    "# 获取 API 调用中使用的总令牌数。这用于跟踪令牌限制，并计算在实例之间暂停脚本执行的时间。\n",
    "total_tokens = response[\"usage\"][\"total_tokens\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所谓的多轮对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型和对话消息列表\n",
    "MODEL = \"gpt-4\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"As an experienced high school teacher with years of teaching expertise\"}\n",
    "]\n",
    "\n",
    "# 循环遍历所有问题，进行多轮对话\n",
    "for i, question in enumerate(train_xy_instance):\n",
    "    # 添加用户消息\n",
    "    messages.append({\"role\": \"user\", \"content\": question})\n",
    "    \n",
    "    # 调用 OpenAI API 获取响应\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    # 获取模型的响应\n",
    "    generation = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    \n",
    "    # 添加助手的响应到消息列表中，以便下一轮对话中参考\n",
    "    messages.append({\"role\": \"assistant\", \"content\": generation})\n",
    "    \n",
    "    # 获取 API 调用中使用的总令牌数（用于跟踪和限速）\n",
    "    total_tokens = response[\"usage\"][\"total_tokens\"]\n",
    "    \n",
    "    # 打印当前对话的状态（可选）\n",
    "    print(f\"User: {question}\")\n",
    "    print(f\"Assistant: {generation}\\n\")\n",
    "\n",
    "# 输出最终的对话消息列表\n",
    "print(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  result vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in results:\n",
    "  # Student response\n",
    "  print(res[IN_COLS[1]])\n",
    "\n",
    "  # Model generation\n",
    "  print(res[\"model_generation\"])\n",
    "\n",
    "  # Total number of tokens (prompt + generation)\n",
    "  print(res[\"total_tokens\"])\n",
    "\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_formatted = [list(results[i].values()) for i in range(len(results))]\n",
    "# Define DataFrame columns\n",
    "cols = list(results[0].keys())\n",
    "\n",
    "# Create DataFrame for generations\n",
    "df_results = pd.DataFrame(results_formatted, columns = cols)\n",
    "df_results.head(10)\n",
    "# Convert dtypes to string to prevent formatting errors\n",
    "for col in df_results:\n",
    "  df_results[col] = df_results[col].astype(str)\n",
    "df_results.dtypes\n",
    "# Save generations\n",
    "df_results.to_csv(path_or_buf=GENERATIONS_PATH, index=False)\n",
    "# Import saved generations to make sure there were no formatting issues when saving\n",
    "df_results_import = pd.read_csv(GENERATIONS_PATH)\n",
    "\n",
    "for col in df_results_import:\n",
    "  df_results_import[col] = df_results_import[col].astype(str)\n",
    "assert df_results_import.equals(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算相关指标\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "y_pred = ''\n",
    "y_true = ''\n",
    "classification_report(y_true, y_pred, digits=3)\n",
    "\n",
    "#计算混淆矩阵\n",
    "cf_matrix = confusion_matrix(\n",
    "    y_true='',\n",
    "    y_pred='')\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labs = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labs = np.asarray(labs).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labs, fmt='', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
